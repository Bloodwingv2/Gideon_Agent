{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efe33ebf",
   "metadata": {},
   "source": [
    "Local Ollama LLM MCP TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af5425c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Session termination failed: 400\n",
      "Session termination failed: 400\n"
     ]
    }
   ],
   "source": [
    "# Import annotations and typeddictionary\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Import langchain model initilization\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "# Import tools library\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# Import Langchain BaseMessage, AIMessage, ToolMessage\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage\n",
    "\n",
    "# Import ToolNode\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# Import reducer/merger function to append to state\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# Import MCP for testing\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "\n",
    "# import asynchronous functions\n",
    "import asyncio\n",
    "\n",
    "# Initialze offline LLM\n",
    "ollama_model = init_chat_model(\"ollama:llama3.2:latest\")\n",
    "\n",
    "# Define AgentState\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    \n",
    "# Define list of MCP servers\n",
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"Chrome-MCP-Server\": {\n",
    "            \"url\": \"http://127.0.0.1:12306/mcp\",\n",
    "            \"transport\": \"streamable_http\",\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "mcp_tools = await client.get_tools()\n",
    "#print(mcp_tools)\n",
    "\n",
    "ollama_mcp = ollama_model.bind_tools(mcp_tools)\n",
    "\n",
    "async def model_call(state:AgentState) -> AgentState:\n",
    "    system_prompt = SystemMessage(content=\"Your Name is Gideon, You have a set of tools connected to a Chrome MCP Server which can open webpages, Take screenshots, Add Bookmarks, delete Bookmarks and a lot more use these tools when necessary otherwise answer the question\")\n",
    "    response = ollama_mcp.invoke([system_prompt] + state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Conditional edge function\n",
    "def should_continue(state:AgentState):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if not last_message.tool_calls:\n",
    "        return \"end\"\n",
    "    else:\n",
    "        return \"continue\"\n",
    "    \n",
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"Gideon\", model_call)\n",
    "\n",
    "# Set Tool Node\n",
    "tool_node = ToolNode(tools=mcp_tools)\n",
    "\n",
    "graph.add_node(\"Tools\", tool_node)\n",
    "\n",
    "# Set Starting Point\n",
    "graph.set_entry_point(\"Gideon\")\n",
    "\n",
    "# Add Conditional Edge\n",
    "graph.add_conditional_edges(\n",
    "    \"Gideon\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue\": \"Tools\",\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "graph.add_edge(\"Tools\", \"Gideon\")\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "input_state = {\"messages\": [HumanMessage(content=\"Hello Gideon!, Open Youtube on google chrome on a new tab and also add a bookmark called as HeroOfTheWest!\")]}\n",
    "result = await app.ainvoke(input_state)\n",
    "\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f10614e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAERCAIAAADZj/2iAAAQAElEQVR4nOydB3wUxR7HZ/dqeichPYHQQgtNUAkIQRREEClSpAiCgCJNfKLSRGmCPEQQVECKAlICSg9SnoD0gIRASIAQAmmk55Jc2/e/2+RySS4hidm7ud354mfdnZndu9z+dvY//5n5j5hhGEQg8B0xIhAEABE6QRAQoRMEARE6QRAQoRMEARE6QRAIVOj5Gdros1npj4qLizQaNVIXaRmkpRCty4ONFukOKRr+h2h9DkIMpfsHaVpGt2NIKdlBFBTWnaEt+QhKzOgyNLp93R6iSjJECGlKy+jLU/qPhR3DBXVZIqTVlh0CEhtKLKZldiIvf3mbbi5yW0SoOZSg/Oj52Zrff3icmVoM+pPIaJkNLZXTlIhSFWp0StT/EqAwyC0RJoNoEaXV6DJomtIpT0TppMz+aBTF7uiyYAd2Kd0pLLQY6Z4IDXtclmG4ICondLgsY3w6RetvjdHNkdqINWqtWskUKbQqlUYsoRv4yAd+4I0INUBAQt8070F+rsreSRLa2bHTK67Iyvlrf+adq7mFuWoXT9mI//ghQrUIQuiHNqUm3Mht4CcfOoN3gtCgX5YnZaUXt+vu2qWf1T+93MF/oW9Z9FBZpBm/KAjxl7RHyn3fPXL2kA2d4YMIpuC50H/75hFFUYOmCeL2b/0iqWEjecRwD0SoBJ+F/tPc+44ussHTBdRc+/mLRJGYGvmJPyKUh0Y8ZfuyR0JTOTD68wBwy+xf/xgRysNPoZ89kFmQpRSaylnGzAtIji9MvFWICEbwU+jRp7N6jxKug7lNuPORLaRSLwcPhb5ndbKdoziguRwJlRf6uUFn1qnfMhChFB4KPTWxMHyA0D0PLTo6xV3LRYRS+Cb0sweeiqR0cBuzDgTZtWvXvHnzUO3p1atXcnIy4oCuA91USuZBDLHUS+Cb0BOu57t5SZF5uXXrFqo9T548ycrKQpzh4Cy+HJWJCHr4NnqxIE/TNtwZccODBw++//77K1euQOdD69atR40a1bZt2wkTJly9ehVyDx48uG3bNl9fX9ieP38+ISHB3d29W7dukyZNkst1DYbZs2eLRKKGDRtu2bJl4sSJ69evh8T+/ftDmRUrVqD6xivI5mFsASLo4ZfQNUirYVp3c0IcoFQqQdMdO3b89ttvQa8//PDD9OnTDx8+vGHDhjFjxgQEBCxYsACK/fjjj5s3b160aJGzs3NeXt7y5cuh8NSpUyFLIpHExcUVFBSsXLmyVatWzZs3nzZt2v79+318OOm4DW5pnxCdhwh6eCX0ezEKmjNbLDExMTMzc9iwYc2aNYPDJUuWQEWuVqsrFBs5cmTPnj2DgkqG1ly/fv3cuXOs0CmKevz48datW9kKnmsat7I9SmKZlMIroefnKLlrdPj7+7u4uMyfP79Pnz7t27dv06ZNhw4dKheDahvsFmibQuXNPgaurmWDCuEBMI/KddC60fL5mcieDGrkWWNUoy6dEsEBMpkMzJUXX3zxl19+GTdu3IABAw4dOlS5GBg2YMy88cYbkZGRly9fHjt2bIWLIDMC7xDGMJ1J2PBK6HbOUoQoxBmBgYFgVf/xxx9gZDdu3Hju3Lm3b982LgCN1D179gwdOhSE7uXlBSlgpiMLomUcXEWIwDOhBzSzNcxSq3fA5XLgwAHYAdsjPDx86dKlYrE4NjbWuIxKpSosLGzQoAF7CO3XM2fOIAuRFFtEcfjUWxm8ErrMRre9czkfcUBOTs7ChQtXrVqVlJQEDdNNmzaBCQ6WOmT5+fndvHnz0qVL+fn5UOvD8/Do0aPs7GwoD/7H3Nxc8LRUviCUhO3x48fhXMQBcdF5tIgovQS+dRjZOohjL3HS9Q2anjNnDvgTwSx58803r127Bj714OBgyBo4cCBYw1OmTLl79+5XX30FVf6gQYPAiO/UqdP7778PhxEREeBvqXBB8Lj369cPLgJmPeKAx/cUTq4SRNDDt4kXx7elJvyT/97SRkjwrJkR33WAR5twTnoVrA6+1ei9RnqqlMzTJyokbK6eyKZFiKjcAA8DGLk3lB3bmjJsdpUT/sGoAAO6crpGo6FpmqqiBQfuQujsRBwQHR0NzhyTWdV/pZMnT1aVdflEpm8ICXFUBj/njH43K2HcwkZVxbJKSUnRarWolnh7cziTo7IFXxOq+kq3L+Sf2pv23tJgRCiFnyHp/EJstn55/90vTYe4YD3cWFG/T9Gp3alhL7khghH8nEr3+kRvmkYHf0pBwuPX5UmO7tLn+nA1hNNK4W0UgHFfBCXFKS4dyUZC4vf1KQU56uEfkwh1FeF5AKMNn9wLaef00mBBvMd3f5NcXKwlcRhNwv+QdKB1eyfJcL7f/s0LExkNM3ZBICKYQhBBRrcufpiboWz1vFP4mzycNH3059S7N/K8A20GfkACL1aJUMJG3zib+799abDj28i2xzBPB2erH9OXkaQ8sz/jyYNCmQ3dd6xPw2Bzz5S1LoS1EMDFo1k3/souzNeIJZTcXuzgKLZzklAiRlVcNmibDfhvdIh0Pnd9iH5d5wxVsqYFrV8Oo2x9C31If1o/16HkF6XhX8mlSi5SUrQk2r8hUb8EAWNYLUMkpjRqo6UHStMlcpFWhQpyVQW5msJ8NZRxcpd26Ona/Dl7RHgWwhK6gQtHsx/FKfKy1FqNVg0boxED5URZtqqF4bhEppR+hymfrCuM9OlwCZqCLk2GMXHNklMM68DodW74IJFYP4Ok9KMN6VIZQ4vEYilycJYGNLMN60G692uBQIXONcuWLQsMDBwyZAgi4AFZlY4T1Gq1WEx+W4wgN4MTiNBxg9wMTiBCxw1yMzhBpVJJJGR2D0YQoXMCqdFxg9wMTiBCxw1yMziBCB03yM3gBGKj4wYROieQGh03yM3gBCJ03CA3gxOI0HGD3AxOIELHDXIzOAGEThqjWEGEzgmkRscNcjM4gQgdN8jN4AQidNwgN4MToMOICB0ryM3gBFKj4wa5GZxAhI4b5GZwAhE6bpCbUf8wDKPVakUishwcRhCh1z9k6CKGEKHXP8RuwRByP+ofMF18fX0RASeI0OsfqM4fPnyICDhBhF7/gNDBekEEnCBCr3/A36LRaBABJ3i7tItlAa2TSh0riNA5gVgvuEFMF04gQscNInROIELHDSJ0TiBCxw0idE4gQscNInROIELHDSJ0TiBCxw0idE4gQscNInROIELHDSJ0TiBCxw0idE4gQscNInROIELHDSJ0TiBCxw2ycnR90q5dO3aH0i2OXgIkbty4EREsChm9WJ907doVtjRNg9BhKxKJ3NzcRo8ejQiWhgi9Phk3bhwo2zglKCioW7duiGBpiNDrk9atWxusF8DOzm7IkCGIgAFE6PXM+PHjPTw82H1fX9+XX34ZETCACL2eCQkJ6dy5M+zIZLLBgwcjAh4Ixety42ReanJhUaHO5QdtRa2WKb+DGPCTaGCDDL8HBYlaVJILP1RpSa22pEBV+wqF4sY/N6Ax2qljJ0qEGA1cCyGjn5ktXJLFfhb7uWwx/db4gqWFyl3EgFwu9g6xC+1shwhVw3+hXz6We+XPDJCSWIqUCt0fa1BwuR34HRiqnJhK93W58E9LGZ9SzT5C+vK6C8C/Spc1FGazjD9Lv2X0J1W4oO6a+vTKyGxolZIRiVG/cT6eQVJEMAXPhZ6aqIxc+6jLa15BrW0Rr7n5V0706aejPg2wcyLBTU3AZ6Gn3FfuX/to+GfBSBgU5qK93957b5lQ/t5awefG6PFfU939bZBgsHFE9k6SyG8fI0Il+Cx0RZ4qKNQeCQm3hvLMdCUiVILPg7rUSq1EKiz/KW3DFBeTaHgm4LPQofWh1grrrjNqrVZNRumZgAzTJQgCInReQelAhMrwXujCstH1A+ARoTK8F7oWCQoKkRrdJMR04RcMIjW6SYjQeQVU5xQZkGoKngtdaK9x3cg0gRlrNYTXQmco8h4nsPBa6LrRrkhQUDQluLdYzeC9jS6s264z0WmidBPwXujCsl20gIaYayYgXpeKqNXqw0cOXLx47vadmMJChZ9fYKeOXQYOHObk6MQW6P9GzzcHDhv19vjK544dN6RN63bTPvwPImAGEXo5kh8/mvPptMynGYMHj+zVq49Sqbx46dz+A7v/PHlsyeLVPt6+UGbokLdbNG+FCFYFv70uqLasXPllenrq92u3+vsHsikRPV+5fz9h8vujIyN3TZk8A1KGDxuDcIWMdakKfntdalUaZWVlXr126e2R4wwqZwkKarR5425PTy/20Nh0efDg3pKl8xIf3m/btsOokeWMmZiYGz9v2XD7doyTs0uXzl1Hj5pgZ1cyUf/hwwer/rsk7m6sSCQODAweM3piWNsOkL5g4X9ApxE9X12ybD5YTS1atHpvwofNm7dEtYFY6CYh3Whl3Lr1D2w7P/di5SyDyo1RqVQff/KBh4cnPAYT3526Y+eWp08z2KxHyUmzZk8uKi5a8+2mLxZ8fe/e3ekzJrDxdeFxev+DsQ0aeG1Y/8t3325ycXb9YtEchUKB9DF4Y27dOB516Pt1Ww8f/EsmlS1eOg/VBn0sA0SoDBF6GRlP02ELwq1h+TP/+zMtLXXK5JnwGEDFPPWD2fn5eWxWVNRhiVgCEoeXA2TNmvn53fg7f509BVm/7d4ulclmzfzMu6GPr6//R7PmQuW9/8Bv7ImFCgWkQBaIvmePV5KSEtlngPAv4XuHEVNri1VrFDdo4RefnDx13HB48sRl45LJyUlyudzLqyF76Obm3qBByUMSE3O9WbNQJydn9hDKeHv73vjnWvduEffux4eENAMds1lgz/j5BsTFxbKHfv6BtrYlkTns7R1gm5eXa0gh1BmeDwGoVcvM3U0XMzEtLcVgqLw9cny/fm/CDngbwTKpUD43N8fGppwEZTI5uwNV++07t17q2cE4NyvzKWzBpePj42ecLrexURSWVNs0/a/esbQuWDVpjZqA5+7FWlmsoaGtRSLR2XOnW7Vqy6ZAM5TdefIkuXJ5R0enwsJydoVCUcDuuLq5w0XGjnnPONfJUVfB29rZge1unA7miq+PP6oPSIdRVfDcRq/VyA9nZxfweOzZ+2vc3dsVslJSTARL8fJsWFRUdO9ePHsYHx+XkZHO7jcKDoE3A3QegTuF/Q8anawzp2mTFrGxN6Ehy5bMzcsFp43hiSJwBO8bo7Wr3qBTE5x6Uz8c9/OWH65FX4b/jhz9/cPp74LdUqF6Bp5/vptUKv165SKQO0h84aJPHEt7TwcNGgF165q1KyALGpTrN6x+Z/xQsM4hC2yhgoL8FSu/TE1NAe/k4iVz5TJ5n1cHIAKX8N50qZ3BCo3LFcvXHTwUefny3wcP7QNTxN8/yM3V/Yf1vwQEBFUobG9v/9WXqzZsWP3a693gxAnvTo06cZjNcnRw/OnHnTt2/Dxx0kjwmkPD9KNZnzcJaQZZvj5+8+Yu2br1x7eGvwatVXCT/3fVjwYXlDYyKwAAEABJREFUO4Ej+Bx7cc2M+BcGeDZu44AEw9kDKQnR+VNWNEaE8pCxLvyCosnsaJMQofMLRktmR5uECJ0gCPgtdDJnlFACv4WuW5gICQkKkXG6piHhLvgFhZDAnu0awns/uvAgOjcF3xujjLDqdBJktCr4LHRdfDbyHifo4fmKF0KTOUUmjVYBCWDEKxhiu1QBETpBEJCFAAiCgM9Cl4hp+IeEhEQsldqQYR0m4PPEC5GUzkguQkIiL1MlkxNrzQR8FrpngDzxTj4SEumPFY1aCWj8fc3hs9D7vesFvrZTv6YjYbBvTZKTm/SF/q6IUAk+zzBi+fGz+xIZ7d/U3sPbTqVR6pKo0n5ymkLakj8fHgn4KUq2Rv3o4JU2/EL68BmlznldUd2aGuxh6Yklx7qA/NqyGAQURTP64xJoGhmix1CIZiht6VV0H0ZT5boAjAqzPnLjD0K6Zpb4SZIiKS5fKqffnlM/0QT4B/+FDvzxY2rKA4VahdRK/YrpBn2XU7Q+2hGbYpxOl3luKHZIAYPKzi09NH4eSg6R8cXLDUGh6PIrDZXPrRB3iRZRJiJYGJ0iklAyG1FAc/ueb7kjQhUIQuhVUVxcHB4efvLkyXoPhTVs2DB/f/+lS5cizigsLOzXr9+2bdu8vLwQ4VkIN/Zibm5ufHz8uXPn6l3lx48fT01NvXXrVkJCAuIMGxubqKioJ0+eKJVKRHgWAhX6xo0bs7KyQkNDRSIRqm+2bNkCTxFIcOfOnYhjwsLC4E8YNGgQiUVaPUIU+u3bt4uKigICAhAHHD16NDExkd2/cOGCYZ87QOhff/01PF2IUDWCs9GhoqVp2tOzprGha8uIESPu3LljOARjfebMmchcrF+/fuLEiYhQCQHV6FCLQ9PT1dWVO5Xv3bv34cOHxil///3348ePkblo1KjRp59+igiVEIrQVSrV2bNnjxw5IpPJEGeAUQ7OEOOU+/fv79+/H5mLiIiIqVOnws7169cRwQhBCH379u2gv549e3IdUT87O9vd3d3Z2RnsZrFYDA8V7Pzxxx/IjLDvK3D4LF68GBFK4f9It/Pnz6elpTk6OiLugZYouzNr1qzXXnute/fuyEIMHDjw4MGDSO9uB0ckEjw8r9E1Gk2DBg2mT5+OzAt8LheOy1rRt29f2B47doxVvMDhrdALCgqgQgW1QfsMmR2tVmtxobP079//4sWL8E5Dwoa3Qt+zZ48FazK1Wo2J0IEFCxZA4wScnsnJyUio8FDo+/btg+2oUaMsGF0favR/uexW/WJvbx8cHDxlypQK3k/hwDehR0VFPXjwAFkaHGz0CkgkksjIyKysLOP1JYUD34Tu5uZm/qZnZfCx0SvQpk0biqL69OkDnlAkJHgidHCijRw5EukHOSEMwMpGrwAIffPmzbt27UJCgidCX7Vq1Zo1axA24GajVwBcrhMmTIAdrH40TrF6oYNRDttPPvkE+iMRNmBrulSgffv2OFh6ZsC6e0bBh5ibm4vwA2fTxZguXbq0aNECdq5cuQKiR/zFumt0Dw+PsWPHIvzA3HQxxslJtwhweno6v4c9WqXQi4uLwVaBnfDwcIQlGLoXq+eVV17p0aMH7OTl5SE+YpVCnzZt2uzZsxHGWJ3QgZ49eyL9AHpeOmSsTOiXL1+G7bp161xcXBDGWKPQWXr16gU9buacLGIerEno27Zti4+PR9aAFdnolYG3paOjY5wexBeq9LpgaKuBfyAkJKRuX8zBwawRCaFGF4ut2KNla2vr6en5+++/y+Vyrl+e8EOZYcR8lTcDGnwIDxiGUSgUdnZ2/v7+df5W5he69dboLCqVClqosOVaCfBbmUHoVnAzsrKyrG6OjPXa6BWQSCSwzcjIgL8IWTNYCx26XWDr6upqdbWjtfSM1hA3Nzd83vB1A18BgblivbUID0wXYyiKYueV5+dba7x5y9+M+/fvgy148+bNylmchqbgFN6YLhWAO/JvxveuWbPGUvGVLCN08NSOGjWK3Ycu6OHDh0NnviG3qEi3HgvXoSk4hWemiwEw2dkhA1YX2dQyQjd20IIJDqI3RM9KT0+XSqXIyuFrjY6MFiPIyclB1kMtfL1JSUn//e9/wcZo2LDhCy+8AOpkFQnp8Eq6e/cuOETBA/j222+3adMG0r/88kv4UXr06LFixYrCwsJmzZqNHz8etlu2bPnll1+QfnzFhAkTwsLCJk2a9PXXXzdv3nzJkiUmT4HCc+fOhe3ChQvZL3P8+HEos3fvXqj4oc36888/s3PdQ0NDX3/99U6dOiHLAdU5L5dvPnbs2KFDh+BtHBgY2K1btz59+iD9H7t48eKq7ho0tJYtWxYdHR0UFMSG37AUNa3RU1NTp0+fDjICLQ4aNOjkyZNr165Fet8fpDdo0OC777775ptvoHMBCrAhjEH3sbGxJ06cWL16dWRkJJh3oGakn7Y8ePBgOOXIkSMDBw5krw/mCtvJYvKU6oFvsm/fPtA3yL1r166LFi363//+hywHL6tzuOMrV65s3Ljxpk2bxowZAz/4xo0bUalnrKq7tmrVquTkZJDE559/npiYCJURshA1FTr8YfAHgEbbtm0Lj+bo0aNZDyukQ73+4YcfQjXv4+MDoodn2hCEDfYhBbJAwd27d3/06FE1YbzZ90OtTkH6jq2oqKghQ4bAt4KO6969e8NZ7BvDUvDSQIdaqWXLlu+//z7UZaABeG9DvylUc9XctadPn545cwYqNajdwUAdN26cBb0LNRU6+EbgaTbcv5dffnnKlCmGdEN3NxgSIHcwY9hDPz8/Q5vS3t4emfJPQd8bbKGrueanGAOfBQ0j40kDrVu3hm9lwQkZ1jLroubAo3vr1q0OHToYUkDrkMj6yuDuw10DxbPuYMNde/LkCewYx6Fv0qQJshA1tdELCgrY5nYFMjMzvb29jVNAsoaIss/0Jefl5VUoU1v3M3wx2FaOQQ6VjXniLVYGnjFjTfAAqEqgPtqsxzjd4GqEuwZyh0Pj35yta4x7tQ3VmfmpqdDt7OxMmhBQ+1boMwOVQ6WOagacXrcwI4azoNMOtmA7VXjejP2VZmby5MlgrSIeAQIFvUZERLz44ovG6WCrGB/C3TRuhbOiN5aHBdefqanQ4aVz8OBBeCmzVsqpU6eOHj0KzT5IBxMZHnfWZIcaGpww8IvU8LLwimdPfCbwZjTuqgArkN0BfbOWH+vqQfq6HJxflnLDQ4scrFJ4lSN+ERwcDNaI4UeGO56SklKhNqngF2aXy4uJiQkJCWFPuXbtmkm7wAzU1E5gB7JBRXX16tWzZ89CixuqUpAp+JjAeIB0cO1Bs3r58uUgOyhc/dWgygeb59y5c6BX1kZ/Jk2bNgXvOxjfsA/fAc5l00HQI0eO3L59O9iL8IYFf8ucOXPABYQsweXLl+/cuQP9X4h3jB079vz581C7saY5uBQ//vjjCt1GoATj97O7uzu46bZu3Qp3Ger1pUuXWtDrWtMaHaT5xRdfgLcInKkgZaiz2VnJkA7CAi8HOGTgYQU5gmvpmbVpx44d4ScApzhoFFzySN8BUf0p/fr1g3cFtPqhxQNO3Lfeegu8tmwW1KBQ3+zatQv8tWBigT8eLBlkCWbMmAHeCcRHwOUCvSU7d+786aefwBcMP/L8+fMreFFA9xVSZs2aBWfBXYPqrFevXuDDgKcFWYIqF+vKyMhA5oL9Dpw+7lC7II759NNPw8PDwb+JrB+omOGVi2oJCB0M0dreRzCGzRCTB4sRdvDTWHvkS3atC36ovM6AjY5tlzAu073AVwMWv5UuQgJf3uLdsTgANjr4Z/DsQ8BlzDSY9dY7+hw6BcHZggQPGOLYLluLS40OPQ5sj5rVAQ1xaILzrIeobkBthe10E4xmqoOZDq0ZC3ae1QFwnIG3JzIyEhEq+dGxAqPnDyoD8FvV0K2OCcRoMQbn2Y9V1ugWicIMPa/g1mSHMuPPt99+C979oKAgxDvAeVIHASxbtmzo0KGG3tMaYh5rh8K29YA5169fB6H/+OOPiFDKxYsXGzVqxI4+wg3shH748OHHjx+PGzcO4U2PHj3ANLfUAElCbcGujfzqq69u3rwZc0t93rx5M2fOJCqvwPbt2+/cuYOwBEdnEPS81HBIo0X4888/odFs2RmQeHL16tXU1FSEJTja6NByj4+PB+c0wg941YSHh1tqZBLmgNB9fHwMAR2wAscaHfqQd+7ceeDAAYQfxJ9YDe3atcNT5QjbkHSTJk0yTK3AB+gb8vf379y5MyKYAqqnmJgYhCWYxvD28PCYPHkywomUlJQtW7YYAhwQKnPjxg0XF5fQ0FCEH/gGwkxKStq7dy/CBmK0PJMhQ4bgqXKEs9D9/Pz27NmDibtq3bp1ERER7NxHQlVAn2jN58WbGaxDG69evRqHBVLA7rxw4QL+fVgWZ9++fdeuXUNYgvU6O256kKUBo2XHjh2I8CygRqAoKiwsDOEH7mNddu/enZ2dPX78eGQhFi1a1LJlywEDBiDCswChOzg4gGMK4QfuqzIMGjQItI4sxJkzZ7KysojKawi0RPFUOSKjF6sBfplOnTpdunQJEWrGwYMH3d3dn3vuOYQfVrDOjlKpjI6ORmZnxowZK1euRIQaExsby0aYwhArELpUKv3tt9+OHTvGHlYI/8cR4MKHTquuXbsiQo3p27cvtt3G1mG6pKamDh06FKr2oqIiOzu7uXPn9urVC3FGRkbGyJEj+RpzS5hYwTLeffr0SUtLY/dpmgYHFteTcInRUjeOHz8ul8vxfA3ibrqAoWJQOYtIJOK0F+mHH3544YUXWrRogQi15K4ehCW4C/2zzz6rMPITVM5dSIw7d+6cPn3aUmthWjsRERHdunVDWIK76fLKK680btz4o48+evjwIRvXD4TO3fwjMFrYNagIdcCCK7c8EyvwuoDQ9+3bB95ZtiIHuXO05tOSJUvGjh2L7dQB/IH+tRMnTiAssViNnv5QmZWh1GrKBdGlaJrRaqHeLvMEsdFZGWbq2CWHjhz65/o/UCYtXoRyc5myIqW+Iyhc6kTSn0YxcCWjRKR7smkt0lZIhMJxd+/mJtu36tn79qXckiRjdxRNu7lLPQKsfqVfTklISFAoFD179kT4YQH34vkDT2/+natWa0FJGnX5T9fLC/5RiKqQWA0MpfuHaoipqzGo9POq+CxKDP4eRkRTIW0cX3qL81Dr1gV4fqGuUavV7Nr24C3QaDTgCzZ0feCAuWv0+GjF9XM5bcJdW75ggUhg/5I7F/Ou/vnUuaEsrJsDIpRiY2Nz48YN44BbWq0WDE6EE2a10c/uzzq1O23EJ8HWqHKgaSeHYf8JvBqVeXxLOiKUMmrUKOjFM04B6Y8YMQLhhFmFHnMhu+ULrsjK6dzXIyEmDxFK6dGjR4VuBx8fn/79+yOcMJ/QMx4ptSom9Hmrj27l39yW0tlgxYhQypgxYwxxy8AnBlY7wgzzCcOnl3IAAAueSURBVD0zTckgngwJhj/k6ZN8RCilS5cuhoBT3t7eb775JsIM8wkdPIkVfSxWi0aFePO31BfvvPOOq6sruFzwnKdiBYO6CPXLw7ji2xdzMlOLi/I1KhWjUZl6YkXwNFdMg74HLYOoSol6jzDsuL4Wuhq81Xk3pOv/uae7qPGFdcUYdo3NMod2eWduhetLZDQtQjK5yMFFHBLm2KyjHfoXEKELBjXaszY5/bGuk04E3QJikVgqldhQYqmpNSrgTV++K08nSdCoFlFVK11qKzMubhqjrLLui9KsctcX05QWKQo0eVlFSfFFJ3ZoHF2l3QZ4+IfWZelCIvS6AB1UCNP1NE3zy9KkrFSlxFbsEejiFmCVnQD56cUpd58e2JgstxUPnurn5FG7RR6J0OsCpat3rEPp18/knP09XWojDe0ViKwZew9ZYw9v2Ll/LW3bkgf+TW37TWhY89PN1xilKYTtssJ1wCo8SH/8kHLuj6f+bXwad8E0gFYdCAprEBoR+Ph+0eaFiTU/y4xeFwbxJ+IAg/DXefSpHDBtm78UYO/Gw7FoTcP9tRp6x4rkGpa3gmG6hDoQ+f2Ti8dymnf3Q/wluLN3kQL9NPdBTQoTodcJmqEofKv0S0ezHycUNunKH3OlKgI7eGkZ6tevk55Zkgi9TmgphsG3vXHhaEbjzr5IGIQ875uZoow+nVN9MTMKnUctUZ3Phcb0z9k474GNnUxqWzvvm1XjGewKnqXqy5hP6BRC1uV7rgZoVDNaHE2XtERlQa6q0fPeSEi4BznSYvrY1rRqypjPj65zudRGG9eiL8+Y+Z7JrJe695r7+WJUS+Yv+Dg/P+/r5WvRv0fnKsVR6Ie3psjtOZlQWy/s+X3ZvQfXPvrgV1TfuHg73o3OfvntBlUVwLfDqFGjJitXfM/u79y1NS4u9vPPvmIPnZ1ckGXRuUpxfD3lPVUGdahFNwpv8ApxyXiQnXBN0SjM1mQBfIXu6OAY1rYDu3/8+CGpVGo4JJjk6p85lIiyc+Uq6A3mSG0k105lWZ/Qq+fs2dM/b9mQ+PC+k5Nz48ZNP/zgY09Pr2dmGfj7wtmdO7fcvhPj6uresmWbCeM/cHOrzZRnCsemdXx0vkTK4Q29dPWP85f2PUmNb+jZuG2riK5d3mK7urfunAO/SLs2r+zcu7C4WBHg16pv7/cD/FpCFhxu3z03/t5lOKVLx4GIS2ycZFkZhVXlmnMIQL191uUrF+bO/+jll/vu2nFo3udLUlOfrFq95JlZBuLu3v5kzodhYR03b9w99YPZCQlxS5fNR7UEw07evBy1zJYroV+9fnTnvi98vZvOmbHv1V6Tzpzbsf9QyRp9NC1OTPrnSvThD9/b/NXc02KJdMfehWzWrsgvM54mTRyzZvSwpSlp927HnUWc4eTpoCzWVpVrziEAWlRPbNy0Lrxrj0FvDoc6OzS09eRJM/7++6/bd25Vn2Xg5j/Rcrl85Ih3oKZ/rtPzK5avGzZsDKoN0LDGsEbXKDVSO65aohev7A8OCBvYb7aDvWtIcIfePSecvfBbXn4mmws199A3PnNz9RGJxO1a907PSISUnNz06zejXnrxbajdHR3cXuv9vkTMoVnl6C6vxtthlX70e/fuNmtWtp5l0ya6mbm3b8dUn2WgZau2RUVFn3w67bfd2x8lJ8EjUVvrn9LFw0G4odEyIm4qdK1We//hjSYhZUtZgNYZRnv/QckCDQ08AmWyEuNYLtcNA1YU5mZm6QaieDYIMpzl59MccQcNlSlTVMW0dTPa6PUkjfz8/OLiYpmsrG6wtdX9xApFQTVZxldoEtJsyeLVZ86c2PDDt2vXfdO+XacxoyeCpY6sHHj8NNw8fmq1UqNRHYn6Hv4zTs8rKKnRKVN2aYFC11sJfVeGFKm0LnMmag504lVlNphP6PVVn7MRGIuKypodBXodu7m6V5NV4SJgscB/Y8e8d+XKhT17f53z6bT9kX/WfBQxheWQY1pEMRrEBVKpHPTavm2f1qE9jNPBVqnmLDtbJ9gqVUWGlKLiAsQdGt0kKNsqZpWY0+tSP8oQi8VNmzSPiblhSGH3gxuFVJNlfIXo6CvFymIQuru7R+/er3l5eU+bMUGhUFSIwlMNeI7nkspppUKJuMG7YZPCorzGwe3ZQ7Va9TQr2dmpuoCsLs66DtoHD2+wFguccjfhop0dV30gOWkFdNXjMsxno9fjTIU3Bgz96+ypPXt+zc3LhQ7UtetWtgvrGNK4afVZBm7GXJ+/YPbvf+zNzs66FXtz774doHjWyKnxH4Njf5G9k6i4gCuh9+k16Wbs6QtXDujs9cTobbs+Xb9pCpg01Zzi7NQg0L/N0T83pKUnqlTF23/7nFOnLAhdIq1Sz1bpRwfvYXpG2s7ftq5ZuwI8Jx3ad353/PvPzDIwZPBIkPia775e+c1X0A/V46Xe36zcUEtTRD9hHTOatnc8E8lVrLyggLbTJ23588zPB4+tUSoLwVk+dsRyieQZTp5hb87b8/vSVetGqTWqjmGvdWr3ekzsacQNRXkqD+8qA+ebL5ru7Uu5Ub+kjZ6PV+zJurFlQULYS07P98MurO6amfG+Lb2cvbht8+FJTNT9ARP9fJqYfvbM6V5E/AHLnlHAzVOWnvAUCY/kW5kiMV2VyhGJAsAz+k/22fj5vWoKXL52KPLQCpNZtjaO4Pw2mfVc+/79XpmK6gkw8X/aNtNkFhj9IpHEpBnZv8+MjmF9URXkpOQ2a+eEqsacfnTEGxjDBjNs7WkXT2n8+eSqpv23atE9OLCtyazi4kKZzLTNI5XWpqX+LMDcnzF5q8msoqJ8udzeZJatTZU6To3Lhuq8x7DqLElSo9cFCtdhusCI//h/NyshL03h0MCEOqH/0tCFaUFcXepzakhGYnbfcc8YnEzmjNYVjJscLw/3fPhPGhIGcWcf+TaxDQx9xtNrRqGDM5831gvecbpC2tk3becYe+oh4jtxfyXJ5VT/954918SMQtdaWbzC6mBwHKZrTMRwjz5jvG5F1SKWldUR91eybyObUZ/516QwMV3qCvYPbUBzmxadHWNOPEi7x7eFaJQKbezJRAcXus87NV0UljRG64o1mGHdB7uHdnba892j7MfZvi0a2LriO2+65ty78ESRV9z2RecX33Cr+VnmEzqNuWFbG3SDUq3kXejhJ3lvSVDk90/uX3siktD2bra+oVa5Tmra3ayslHxVkdrVU/bO/EaolphP6FrrCEBbI3STpeptvpQ5GKBvrh3elJJ0VxET9YAWUbSIhv8oEcWoy4b2MvoFKcpuE61L0mcwZasWswF6DG0UNrB/SRdP6bn6dQT0xSl2igoD9Zz+F2NEFKVhDEsA6JZOZnQx/5FaW7LPfg34QIkIaZAGUGu1aq1ITLn7yAZ/GIjqBDFdBMSrY0smiV+Kynkcr1DkqTVqRlluPjFD0ZQhNhNF63ZAflotKltbm9brvmx5FoZ9PhDrVGOff6p0lAQIlk2hSy5Ai/QJ+rPYj2C0lFisLbckFKV7SsRSjVgiksulHr6ytl1dHNz/1TuUCF2IdIxwQhFOSEiYcYYRJRaJeGKki6WIlggouCEPMJ/QGwbYMnxxZjIM3dBfoHGCrBTzSc/RA8kkomvHc5CVc/dSAbyZAloIccy39WLWOrZjb/fYy1Y/WvrqifTQLs6IYFVQZl5X6Olj1c5vkhq1dujQy0NqVXWiUomuRT2Nj87pO66hXxNSnVsZlPkX0Iq/Unjm99TifA24mRhNOXc0g6jKI78YxsR0noprserdueAWqzwN3OTpVX0W0vnHwIFWKR2czhSS2Yrav+Te5iXTA6YJOENZcKW4nPTyUUj0/QWlLlx2pWLEoHJrDVNsDwZTaWlidqVjquKy3FTlKRKU0VPCGKUYcpHR1zCitiu4ErCC4s+SiARC1ZAOI4IgIEInCAIidIIgIEInCAIidIIgIEInCIL/AwAA///EswPsAAAABklEQVQDAOJ4v/BOFpteAAAAAElFTkSuQmCC",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d79c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"Chrome-MCP-Server\": {\n",
    "            \"url\": \"http://127.0.0.1:12306/mcp\",\n",
    "            \"transport\": \"streamable_http\",\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b1cdeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Session termination failed: 400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StructuredTool(name='get_windows_and_tabs', description='Get all currently open browser windows and tabs', args_schema={'type': 'object', 'properties': {}, 'required': []}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x00000230FF53E480>), StructuredTool(name='chrome_navigate', description='Navigate to a URL or refresh the current tab', args_schema={'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'URL to navigate to the website specified'}, 'newWindow': {'type': 'boolean', 'description': 'Create a new window to navigate to the URL or not. Defaults to false'}, 'width': {'type': 'number', 'description': 'Viewport width in pixels (default: 1280)'}, 'height': {'type': 'number', 'description': 'Viewport height in pixels (default: 720)'}, 'refresh': {'type': 'boolean', 'description': 'Refresh the current active tab instead of navigating to a URL. When true, the url parameter is ignored. Defaults to false'}}, 'required': []}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x00000230FF53DC60>), StructuredTool(name='chrome_screenshot', description='Take a screenshot of the current page or a specific element(if you want to see the page, recommend to use chrome_get_web_content first)', args_schema={'type': 'object', 'properties': {'name': {'type': 'string', 'description': 'Name for the screenshot, if saving as PNG'}, 'selector': {'type': 'string', 'description': 'CSS selector for element to screenshot'}, 'width': {'type': 'number', 'description': 'Width in pixels (default: 800)'}, 'height': {'type': 'number', 'description': 'Height in pixels (default: 600)'}, 'storeBase64': {'type': 'boolean', 'description': 'return screenshot in base64 format (default: false) if you want to see the page, recommend set this to be true'}, 'fullPage': {'type': 'boolean', 'description': 'Store screenshot of the entire page (default: true)'}, 'savePng': {'type': 'boolean', 'description': 'Save screenshot as PNG file (default: true)，if you want to see the page, recommend set this to be false, and set storeBase64 to be true'}}, 'required': []}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x00000230FF53CAE0>), StructuredTool(name='chrome_close_tabs', description='Close one or more browser tabs', args_schema={'type': 'object', 'properties': {'tabIds': {'type': 'array', 'items': {'type': 'number'}, 'description': 'Array of tab IDs to close. If not provided, will close the active tab.'}, 'url': {'type': 'string', 'description': 'Close tabs matching this URL. Can be used instead of tabIds.'}}, 'required': []}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x00000230FF53E0C0>), StructuredTool(name='chrome_go_back_or_forward', description='Navigate back or forward in browser history', args_schema={'type': 'object', 'properties': {'isForward': {'type': 'boolean', 'description': 'Go forward in history if true, go back if false (default: false)'}}, 'required': []}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x00000230FF53D6C0>), StructuredTool(name='chrome_get_web_content', description='Fetch content from a web page', args_schema={'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'URL to fetch content from. If not provided, uses the current active tab'}, 'htmlContent': {'type': 'boolean', 'description': 'Get the visible HTML content of the page. If true, textContent will be ignored (default: false)'}, 'textContent': {'type': 'boolean', 'description': 'Get the visible text content of the page with metadata. Ignored if htmlContent is true (default: true)'}, 'selector': {'type': 'string', 'description': 'CSS selector to get content from a specific element. If provided, only content from this element will be returned'}}, 'required': []}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x00000230FF53DA80>), StructuredTool(name='chrome_click_element', description='Click on an element in the current page or at specific coordinates', args_schema={'type': 'object', 'properties': {'selector': {'type': 'string', 'description': 'CSS selector for the element to click. Either selector or coordinates must be provided. if coordinates are not provided, the selector must be provided.'}, 'coordinates': {'type': 'object', 'description': 'Coordinates to click at (relative to viewport). If provided, takes precedence over selector.', 'properties': {'x': {'type': 'number', 'description': 'X coordinate relative to the viewport'}, 'y': {'type': 'number', 'description': 'Y coordinate relative to the viewport'}}, 'required': ['x', 'y']}, 'waitForNavigation': {'type': 'boolean', 'description': 'Wait for page navigation to complete after click (default: false)'}, 'timeout': {'type': 'number', 'description': 'Timeout in milliseconds for waiting for the element or navigation (default: 5000)'}}, 'required': []}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x00000230FF53D760>), StructuredTool(name='chrome_fill_or_select', description='Fill a form element or select an option with the specified value', args_schema={'type': 'object', 'properties': {'selector': {'type': 'string', 'description': 'CSS selector for the input element to fill or select'}, 'value': {'type': 'string', 'description': 'Value to fill or select into the element'}}, 'required': ['selector', 'value']}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x00000230FF53D440>), StructuredTool(name='chrome_get_interactive_elements', description='Get interactive elements from the current page', args_schema={'type': 'object', 'properties': {'textQuery': {'type': 'string', 'description': 'Text to search for within interactive elements (fuzzy search)'}, 'selector': {'type': 'string', 'description': 'CSS selector to filter interactive elements. Takes precedence over textQuery if both are provided.'}, 'includeCoordinates': {'type': 'boolean', 'description': 'Include element coordinates in the response (default: true)'}}, 'required': []}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x00000230FF5E3E20>), StructuredTool(name='chrome_network_request', description='Send a network request from the browser with cookies and other browser context', args_schema={'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'URL to send the request to'}, 'method': {'type': 'string', 'description': 'HTTP method to use (default: GET)'}, 'headers': {'type': 'object', 'description': 'Headers to include in the request'}, 'body': {'type': 'string', 'description': 'Body of the request (for POST, PUT, etc.)'}, 'timeout': {'type': 'number', 'description': 'Timeout in milliseconds (default: 30000)'}}, 'required': ['url']}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x00000230FF5E3CE0>), StructuredTool(name='chrome_network_debugger_start', description='Start capturing network requests from a web page using Chrome Debugger API（with responseBody）', args_schema={'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'URL to capture network requests from. If not provided, uses the current active tab'}}, 'required': []}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x00000230FF5E3C40>), StructuredTool(name='chrome_network_debugger_stop', description='Stop capturing network requests using Chrome Debugger API and return the captured data', args_schema={'type': 'object', 'properties': {}, 'required': []}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x00000230FF5E3D80>), StructuredTool(name='chrome_network_capture_start', description='Start capturing network requests from a web page using Chrome webRequest API(without responseBody)', args_schema={'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'URL to capture network requests from. If not provided, uses the current active tab'}}, 'required': []}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x00000230FF5E3EC0>), StructuredTool(name='chrome_network_capture_stop', description='Stop capturing network requests using webRequest API and return the captured data', args_schema={'type': 'object', 'properties': {}, 'required': []}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x00000230FF5E3F60>), StructuredTool(name='chrome_keyboard', description='Simulate keyboard events in the browser', args_schema={'type': 'object', 'properties': {'keys': {'type': 'string', 'description': 'Keys to simulate (e.g., \"Enter\", \"Ctrl+C\", \"A,B,C\" for sequence)'}, 'selector': {'type': 'string', 'description': 'CSS selector for the element to send keyboard events to (optional, defaults to active element)'}, 'delay': {'type': 'number', 'description': 'Delay between key sequences in milliseconds (optional, default: 0)'}}, 'required': ['keys']}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x00000230FF61C040>), StructuredTool(name='chrome_history', description='Retrieve and search browsing history from Chrome', args_schema={'type': 'object', 'properties': {'text': {'type': 'string', 'description': 'Text to search for in history URLs and titles. Leave empty to retrieve all history entries within the time range.'}, 'startTime': {'type': 'string', 'description': 'Start time as a date string. Supports ISO format (e.g., \"2023-10-01\", \"2023-10-01T14:30:00\"), relative times (e.g., \"1 day ago\", \"2 weeks ago\", \"3 months ago\", \"1 year ago\"), and special keywords (\"now\", \"today\", \"yesterday\"). Default: 24 hours ago'}, 'endTime': {'type': 'string', 'description': 'End time as a date string. Supports ISO format (e.g., \"2023-10-31\", \"2023-10-31T14:30:00\"), relative times (e.g., \"1 day ago\", \"2 weeks ago\", \"3 months ago\", \"1 year ago\"), and special keywords (\"now\", \"today\", \"yesterday\"). Default: current time'}, 'maxResults': {'type': 'number', 'description': 'Maximum number of history entries to return. Use this to limit results for performance or to focus on the most relevant entries. (default: 100)'}, 'excludeCurrentTabs': {'type': 'boolean', 'description': \"When set to true, filters out URLs that are currently open in any browser tab. Useful for finding pages you've visited but don't have open anymore. (default: false)\"}}, 'required': []}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x00000230FF61C0E0>), StructuredTool(name='chrome_bookmark_search', description='Search Chrome bookmarks by title and URL', args_schema={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'Search query to match against bookmark titles and URLs. Leave empty to retrieve all bookmarks.'}, 'maxResults': {'type': 'number', 'description': 'Maximum number of bookmarks to return (default: 50)'}, 'folderPath': {'type': 'string', 'description': 'Optional folder path or ID to limit search to a specific bookmark folder. Can be a path string (e.g., \"Work/Projects\") or a folder ID.'}}, 'required': []}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x00000230FF61C180>), StructuredTool(name='chrome_bookmark_add', description='Add a new bookmark to Chrome', args_schema={'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'URL to bookmark. If not provided, uses the current active tab URL.'}, 'title': {'type': 'string', 'description': 'Title for the bookmark. If not provided, uses the page title from the URL.'}, 'parentId': {'type': 'string', 'description': 'Parent folder path or ID to add the bookmark to. Can be a path string (e.g., \"Work/Projects\") or a folder ID. If not provided, adds to the \"Bookmarks Bar\" folder.'}, 'createFolder': {'type': 'boolean', 'description': 'Whether to create the parent folder if it does not exist (default: false)'}}, 'required': []}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x00000230FF61C220>), StructuredTool(name='chrome_bookmark_delete', description='Delete a bookmark from Chrome', args_schema={'type': 'object', 'properties': {'bookmarkId': {'type': 'string', 'description': 'ID of the bookmark to delete. Either bookmarkId or url must be provided.'}, 'url': {'type': 'string', 'description': 'URL of the bookmark to delete. Used if bookmarkId is not provided.'}, 'title': {'type': 'string', 'description': 'Title of the bookmark to help with matching when deleting by URL.'}}, 'required': []}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x00000230FF61C2C0>), StructuredTool(name='search_tabs_content', description='search for related content from the currently open tab and return the corresponding web pages.', args_schema={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'the query to search for related content.'}}, 'required': ['query']}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x00000230FF61C360>), StructuredTool(name='chrome_inject_script', description='inject the user-specified content script into the webpage. By default, inject into the currently active tab', args_schema={'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'If a URL is specified, inject the script into the webpage corresponding to the URL.'}, 'type': {'type': 'string', 'description': 'the javaScript world for a script to execute within. must be ISOLATED or MAIN'}, 'jsScript': {'type': 'string', 'description': 'the content script to inject'}}, 'required': ['type', 'jsScript']}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x00000230FF61C400>), StructuredTool(name='chrome_send_command_to_inject_script', description='if the script injected using chrome_inject_script listens for user-defined events, this tool can be used to trigger those events', args_schema={'type': 'object', 'properties': {'tabId': {'type': 'number', 'description': 'the tab where you previously injected the script(if not provided,  use the currently active tab)'}, 'eventName': {'type': 'string', 'description': 'the eventName your injected content script listen for'}, 'payload': {'type': 'string', 'description': 'the payload passed to event, must be a json string'}}, 'required': ['eventName']}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x00000230FF61C4A0>), StructuredTool(name='chrome_console', description='Capture and retrieve all console output from the current active browser tab/page. This captures console messages that existed before the tool was called.', args_schema={'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'URL to navigate to and capture console from. If not provided, uses the current active tab'}, 'includeExceptions': {'type': 'boolean', 'description': 'Include uncaught exceptions in the output (default: true)'}, 'maxMessages': {'type': 'number', 'description': 'Maximum number of console messages to capture (default: 100)'}}, 'required': []}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x00000230FF61C540>)]\n"
     ]
    }
   ],
   "source": [
    "tools_mcp = await client.get_tools()\n",
    "print(tools_mcp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1a57501",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Session termination failed: 400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Add a new bookmark named mcp', additional_kwargs={}, response_metadata={}, id='aac345b7-6284-4f0e-9b63-9fcb1c608820'), AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2:latest', 'created_at': '2025-08-23T10:19:59.8820921Z', 'done': True, 'done_reason': 'stop', 'total_duration': 4553511800, 'load_duration': 174482300, 'prompt_eval_count': 2833, 'prompt_eval_duration': 2874038400, 'eval_count': 35, 'eval_duration': 1501807000, 'model_name': 'llama3.2:latest'}, id='run--fca292f8-82ef-41ef-9870-d815d90f37b5-0', tool_calls=[{'name': 'chrome_bookmark_add', 'args': {'createFolder': False, 'parentId': '', 'title': 'mcp', 'url': ''}, 'id': '247b380d-6740-4b97-b840-f37c0e07d0e3', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2833, 'output_tokens': 35, 'total_tokens': 2868}), ToolMessage(content='{\"status\":\"success\",\"message\":\"Tool executed successfully\",\"data\":{\"content\":[{\"type\":\"text\",\"text\":\"{\\\\n  \\\\\"success\\\\\": true,\\\\n  \\\\\"message\\\\\": \\\\\"Bookmark added successfully\\\\\",\\\\n  \\\\\"bookmark\\\\\": {\\\\n    \\\\\"id\\\\\": \\\\\"236\\\\\",\\\\n    \\\\\"title\\\\\": \\\\\"mcp\\\\\",\\\\n    \\\\\"url\\\\\": \\\\\"https://www.google.com/search?q=create+react+agent+import&oq=create+react+agent+import&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQABiABDIHCAIQABiABDIHCAMQABiABDIHCAQQABiABDIHCAUQABiABDIHCAYQABiABDIHCAcQABiABDIHCAgQABiABDIHCAkQABiABNIBCDQyMzlqMGo3qAIAsAIA&sourceid=chrome&ie=UTF-8\\\\\",\\\\n    \\\\\"dateAdded\\\\\": 1755944400363,\\\\n    \\\\\"folderPath\\\\\": \\\\\"Bookmarks bar\\\\\"\\\\n  },\\\\n  \\\\\"folderCreated\\\\\": false\\\\n}\"}],\"isError\":false}}', name='chrome_bookmark_add', id='ea81c846-b960-4b8e-abed-5f0faf5a24b6', tool_call_id='247b380d-6740-4b97-b840-f37c0e07d0e3'), AIMessage(content='The bookmark \"mcp\" has been added successfully. The new bookmark is located in the \"Bookmarks bar\" folder and its URL is https://www.google.com/search?q=create+react+agent+import&oq=create+react+agent+import&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQABiABDIHCAIQABiABDIHCAMQABiABDIHCAQQABiABDIHCAUQABiABDIHCAYQABiABDIHCAcQABiABDIHCAgQABiABDIHCAkQABiABNIBCDQyMzlqMGo3qAIAsAIA&sourceid=chrome&ie=UTF-8.', additional_kwargs={}, response_metadata={'model': 'llama3.2:latest', 'created_at': '2025-08-23T10:20:08.2199125Z', 'done': True, 'done_reason': 'stop', 'total_duration': 7783048800, 'load_duration': 204747300, 'prompt_eval_count': 352, 'prompt_eval_duration': 255206900, 'eval_count': 166, 'eval_duration': 7317675200, 'model_name': 'llama3.2:latest'}, id='run--89b7305b-3004-480e-be76-0cafda409172-0', usage_metadata={'input_tokens': 352, 'output_tokens': 166, 'total_tokens': 518})]}\n"
     ]
    }
   ],
   "source": [
    "agent = create_react_agent(\n",
    "    ollama_model,\n",
    "    tools_mcp\n",
    ")\n",
    "chrome_response = await agent.ainvoke(\n",
    "    {\"messages\": \"Add a new bookmark named mcp\"} # Navigation and creation of new window works! Tried with Google Maps! # take a screenshot works but limited by google api # add a new bookmark works!\n",
    "\n",
    ")\n",
    "print(chrome_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e539fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Session termination failed: 400\n",
      "Session termination failed: 400\n",
      "Session termination failed: 400\n"
     ]
    },
    {
     "ename": "APIStatusError",
     "evalue": "Error code: 413 - {'error': {'message': 'Request too large for model `llama-3.1-8b-instant` in organization `org_01jqdvdktxefwb699chevnkj00` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 88591, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAPIStatusError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m load_dotenv(\u001b[33m\"\u001b[39m\u001b[33m.env\u001b[39m\u001b[33m\"\u001b[39m, override = \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      3\u001b[39m agent = create_react_agent(\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mgroq:llama-3.1-8b-instant\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m     tools_mcp\n\u001b[32m      6\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m chrome_response = \u001b[38;5;28;01mawait\u001b[39;00m agent.ainvoke(\n\u001b[32m      8\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mPlay thick of it song on youtube from KSI\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m      9\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Github Projects\\Gideon_Agent\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:3112\u001b[39m, in \u001b[36mPregel.ainvoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3109\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3110\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3112\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.astream(\n\u001b[32m   3113\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   3114\u001b[39m     config,\n\u001b[32m   3115\u001b[39m     context=context,\n\u001b[32m   3116\u001b[39m     stream_mode=[\u001b[33m\"\u001b[39m\u001b[33mupdates\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   3117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode == \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3118\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[32m   3119\u001b[39m     print_mode=print_mode,\n\u001b[32m   3120\u001b[39m     output_keys=output_keys,\n\u001b[32m   3121\u001b[39m     interrupt_before=interrupt_before,\n\u001b[32m   3122\u001b[39m     interrupt_after=interrupt_after,\n\u001b[32m   3123\u001b[39m     durability=durability,\n\u001b[32m   3124\u001b[39m     **kwargs,\n\u001b[32m   3125\u001b[39m ):\n\u001b[32m   3126\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode == \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   3127\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) == \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Github Projects\\Gideon_Agent\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2939\u001b[39m, in \u001b[36mPregel.astream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2937\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m loop.amatch_cached_writes():\n\u001b[32m   2938\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2939\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner.atick(\n\u001b[32m   2940\u001b[39m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop.tasks.values() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t.writes],\n\u001b[32m   2941\u001b[39m     timeout=\u001b[38;5;28mself\u001b[39m.step_timeout,\n\u001b[32m   2942\u001b[39m     get_waiter=get_waiter,\n\u001b[32m   2943\u001b[39m     schedule_task=loop.aaccept_push,\n\u001b[32m   2944\u001b[39m ):\n\u001b[32m   2945\u001b[39m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[32m   2946\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m _output(\n\u001b[32m   2947\u001b[39m         stream_mode,\n\u001b[32m   2948\u001b[39m         print_mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2951\u001b[39m         asyncio.QueueEmpty,\n\u001b[32m   2952\u001b[39m     ):\n\u001b[32m   2953\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m o\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Github Projects\\Gideon_Agent\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:295\u001b[39m, in \u001b[36mPregelRunner.atick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    293\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m arun_with_retry(\n\u001b[32m    296\u001b[39m         t,\n\u001b[32m    297\u001b[39m         retry_policy,\n\u001b[32m    298\u001b[39m         stream=\u001b[38;5;28mself\u001b[39m.use_astream,\n\u001b[32m    299\u001b[39m         configurable={\n\u001b[32m    300\u001b[39m             CONFIG_KEY_CALL: partial(\n\u001b[32m    301\u001b[39m                 _acall,\n\u001b[32m    302\u001b[39m                 weakref.ref(t),\n\u001b[32m    303\u001b[39m                 stream=\u001b[38;5;28mself\u001b[39m.use_astream,\n\u001b[32m    304\u001b[39m                 retry_policy=retry_policy,\n\u001b[32m    305\u001b[39m                 futures=weakref.ref(futures),\n\u001b[32m    306\u001b[39m                 schedule_task=schedule_task,\n\u001b[32m    307\u001b[39m                 submit=\u001b[38;5;28mself\u001b[39m.submit,\n\u001b[32m    308\u001b[39m                 loop=loop,\n\u001b[32m    309\u001b[39m             ),\n\u001b[32m    310\u001b[39m         },\n\u001b[32m    311\u001b[39m     )\n\u001b[32m    312\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    313\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Github Projects\\Gideon_Agent\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:137\u001b[39m, in \u001b[36marun_with_retry\u001b[39m\u001b[34m(task, retry_policy, stream, match_cached_writes, configurable)\u001b[39m\n\u001b[32m    135\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m task.proc.ainvoke(task.input, config)\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    139\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Github Projects\\Gideon_Agent\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:706\u001b[39m, in \u001b[36mRunnableSeq.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    704\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    705\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m706\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.create_task(\n\u001b[32m    707\u001b[39m             step.ainvoke(\u001b[38;5;28minput\u001b[39m, config, **kwargs), context=context\n\u001b[32m    708\u001b[39m         )\n\u001b[32m    709\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    710\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28;01mawait\u001b[39;00m step.ainvoke(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Github Projects\\Gideon_Agent\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:465\u001b[39m, in \u001b[36mRunnableCallable.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    463\u001b[39m         run = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    464\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m465\u001b[39m         ret = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.create_task(coro, context=context)\n\u001b[32m    466\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    467\u001b[39m     ret = \u001b[38;5;28;01mawait\u001b[39;00m coro\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Github Projects\\Gideon_Agent\\.venv\\Lib\\site-packages\\langgraph\\prebuilt\\chat_agent_executor.py:655\u001b[39m, in \u001b[36mcreate_react_agent.<locals>.acall_model\u001b[39m\u001b[34m(state, runtime, config)\u001b[39m\n\u001b[32m    653\u001b[39m     response = cast(AIMessage, \u001b[38;5;28;01mawait\u001b[39;00m dynamic_model.ainvoke(model_input, config))  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m     response = cast(AIMessage, \u001b[38;5;28;01mawait\u001b[39;00m static_model.ainvoke(model_input, config))  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m    657\u001b[39m \u001b[38;5;66;03m# add agent name to the AIMessage\u001b[39;00m\n\u001b[32m    658\u001b[39m response.name = name\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Github Projects\\Gideon_Agent\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3091\u001b[39m, in \u001b[36mRunnableSequence.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3089\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3090\u001b[39m                 part = functools.partial(step.ainvoke, input_, config)\n\u001b[32m-> \u001b[39m\u001b[32m3091\u001b[39m             input_ = \u001b[38;5;28;01mawait\u001b[39;00m coro_with_context(part(), context, create_task=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   3092\u001b[39m     \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3093\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Github Projects\\Gideon_Agent\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5454\u001b[39m, in \u001b[36mRunnableBindingBase.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5447\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5448\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mainvoke\u001b[39m(\n\u001b[32m   5449\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5452\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5453\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5454\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bound.ainvoke(\n\u001b[32m   5455\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   5456\u001b[39m         \u001b[38;5;28mself\u001b[39m._merge_configs(config),\n\u001b[32m   5457\u001b[39m         **{**\u001b[38;5;28mself\u001b[39m.kwargs, **kwargs},\n\u001b[32m   5458\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Github Projects\\Gideon_Agent\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:405\u001b[39m, in \u001b[36mBaseChatModel.ainvoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    395\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    396\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mainvoke\u001b[39m(\n\u001b[32m    397\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    402\u001b[39m     **kwargs: Any,\n\u001b[32m    403\u001b[39m ) -> BaseMessage:\n\u001b[32m    404\u001b[39m     config = ensure_config(config)\n\u001b[32m--> \u001b[39m\u001b[32m405\u001b[39m     llm_result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.agenerate_prompt(\n\u001b[32m    406\u001b[39m         [\u001b[38;5;28mself\u001b[39m._convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[32m    407\u001b[39m         stop=stop,\n\u001b[32m    408\u001b[39m         callbacks=config.get(\u001b[33m\"\u001b[39m\u001b[33mcallbacks\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    409\u001b[39m         tags=config.get(\u001b[33m\"\u001b[39m\u001b[33mtags\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    410\u001b[39m         metadata=config.get(\u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    411\u001b[39m         run_name=config.get(\u001b[33m\"\u001b[39m\u001b[33mrun_name\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    412\u001b[39m         run_id=config.pop(\u001b[33m\"\u001b[39m\u001b[33mrun_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    413\u001b[39m         **kwargs,\n\u001b[32m    414\u001b[39m     )\n\u001b[32m    415\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m, llm_result.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m]).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Github Projects\\Gideon_Agent\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1017\u001b[39m, in \u001b[36mBaseChatModel.agenerate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1008\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1009\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34magenerate_prompt\u001b[39m(\n\u001b[32m   1010\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1014\u001b[39m     **kwargs: Any,\n\u001b[32m   1015\u001b[39m ) -> LLMResult:\n\u001b[32m   1016\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1017\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.agenerate(\n\u001b[32m   1018\u001b[39m         prompt_messages, stop=stop, callbacks=callbacks, **kwargs\n\u001b[32m   1019\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Github Projects\\Gideon_Agent\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:975\u001b[39m, in \u001b[36mBaseChatModel.agenerate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    962\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[32m    963\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(\n\u001b[32m    964\u001b[39m             *[\n\u001b[32m    965\u001b[39m                 run_manager.on_llm_end(\n\u001b[32m   (...)\u001b[39m\u001b[32m    973\u001b[39m             ]\n\u001b[32m    974\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m975\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions[\u001b[32m0\u001b[39m]\n\u001b[32m    976\u001b[39m flattened_outputs = [\n\u001b[32m    977\u001b[39m     LLMResult(generations=[res.generations], llm_output=res.llm_output)  \u001b[38;5;66;03m# type: ignore[list-item, union-attr]\u001b[39;00m\n\u001b[32m    978\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[32m    979\u001b[39m ]\n\u001b[32m    980\u001b[39m llm_output = \u001b[38;5;28mself\u001b[39m._combine_llm_outputs([res.llm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Github Projects\\Gideon_Agent\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1145\u001b[39m, in \u001b[36mBaseChatModel._agenerate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1143\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1144\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._agenerate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1145\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._agenerate(\n\u001b[32m   1146\u001b[39m         messages, stop=stop, run_manager=run_manager, **kwargs\n\u001b[32m   1147\u001b[39m     )\n\u001b[32m   1148\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1149\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._agenerate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Github Projects\\Gideon_Agent\\.venv\\Lib\\site-packages\\langchain_groq\\chat_models.py:548\u001b[39m, in \u001b[36mChatGroq._agenerate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    543\u001b[39m message_dicts, params = \u001b[38;5;28mself\u001b[39m._create_message_dicts(messages, stop)\n\u001b[32m    544\u001b[39m params = {\n\u001b[32m    545\u001b[39m     **params,\n\u001b[32m    546\u001b[39m     **kwargs,\n\u001b[32m    547\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.async_client.create(messages=message_dicts, **params)\n\u001b[32m    549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response, params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Github Projects\\Gideon_Agent\\.venv\\Lib\\site-packages\\groq\\resources\\chat\\completions.py:771\u001b[39m, in \u001b[36mAsyncCompletions.create\u001b[39m\u001b[34m(self, messages, model, exclude_domains, frequency_penalty, function_call, functions, include_domains, include_reasoning, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_effort, reasoning_format, response_format, search_settings, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    577\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    578\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    579\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    626\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    627\u001b[39m ) -> ChatCompletion | AsyncStream[ChatCompletionChunk]:\n\u001b[32m    628\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    629\u001b[39m \u001b[33;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[32m    630\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    769\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m    770\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m    772\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m/openai/v1/chat/completions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    773\u001b[39m         body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[32m    774\u001b[39m             {\n\u001b[32m    775\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages,\n\u001b[32m    776\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m    777\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mexclude_domains\u001b[39m\u001b[33m\"\u001b[39m: exclude_domains,\n\u001b[32m    778\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m    779\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfunction_call\u001b[39m\u001b[33m\"\u001b[39m: function_call,\n\u001b[32m    780\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mfunctions\u001b[39m\u001b[33m\"\u001b[39m: functions,\n\u001b[32m    781\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33minclude_domains\u001b[39m\u001b[33m\"\u001b[39m: include_domains,\n\u001b[32m    782\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33minclude_reasoning\u001b[39m\u001b[33m\"\u001b[39m: include_reasoning,\n\u001b[32m    783\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlogit_bias\u001b[39m\u001b[33m\"\u001b[39m: logit_bias,\n\u001b[32m    784\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mlogprobs\u001b[39m\u001b[33m\"\u001b[39m: logprobs,\n\u001b[32m    785\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_completion_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_completion_tokens,\n\u001b[32m    786\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_tokens,\n\u001b[32m    787\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m    788\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: n,\n\u001b[32m    789\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m    790\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mpresence_penalty\u001b[39m\u001b[33m\"\u001b[39m: presence_penalty,\n\u001b[32m    791\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mreasoning_effort\u001b[39m\u001b[33m\"\u001b[39m: reasoning_effort,\n\u001b[32m    792\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mreasoning_format\u001b[39m\u001b[33m\"\u001b[39m: reasoning_format,\n\u001b[32m    793\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m: response_format,\n\u001b[32m    794\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33msearch_settings\u001b[39m\u001b[33m\"\u001b[39m: search_settings,\n\u001b[32m    795\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m: seed,\n\u001b[32m    796\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m    797\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop,\n\u001b[32m    798\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m    799\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m    800\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m    801\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m    802\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m    803\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_logprobs\u001b[39m\u001b[33m\"\u001b[39m: top_logprobs,\n\u001b[32m    804\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m    805\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m    806\u001b[39m             },\n\u001b[32m    807\u001b[39m             completion_create_params.CompletionCreateParams,\n\u001b[32m    808\u001b[39m         ),\n\u001b[32m    809\u001b[39m         options=make_request_options(\n\u001b[32m    810\u001b[39m             extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m    811\u001b[39m         ),\n\u001b[32m    812\u001b[39m         cast_to=ChatCompletion,\n\u001b[32m    813\u001b[39m         stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    814\u001b[39m         stream_cls=AsyncStream[ChatCompletionChunk],\n\u001b[32m    815\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Github Projects\\Gideon_Agent\\.venv\\Lib\\site-packages\\groq\\_base_client.py:1762\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1748\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1750\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1757\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_AsyncStreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1758\u001b[39m ) -> ResponseT | _AsyncStreamT:\n\u001b[32m   1759\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1760\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n\u001b[32m   1761\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Github Projects\\Gideon_Agent\\.venv\\Lib\\site-packages\\groq\\_base_client.py:1576\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1573\u001b[39m             \u001b[38;5;28;01mawait\u001b[39;00m err.response.aread()\n\u001b[32m   1575\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1576\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1578\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1580\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAPIStatusError\u001b[39m: Error code: 413 - {'error': {'message': 'Request too large for model `llama-3.1-8b-instant` in organization `org_01jqdvdktxefwb699chevnkj00` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 88591, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
      "During task with name 'agent' and id '1abf1fdb-bc78-34f6-4a59-e318f9a31b57'"
     ]
    }
   ],
   "source": [
    "load_dotenv(\".env\", override = True)\n",
    "\n",
    "agent = create_react_agent(\n",
    "    \"groq:llama-3.1-8b-instant\",\n",
    "    tools_mcp\n",
    ")\n",
    "chrome_response = await agent.ainvoke(\n",
    "    {\"messages\": \"Play thick of it song on youtube from KSI\"}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Gideon_Agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
